{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/verschhh/NLP_assignment.ipynb/blob/main/NLP_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_Z-i5i_PcHf"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV9WW7voPcHj"
      },
      "source": [
        "# Natural Language Processing </a>\n",
        "\n",
        "## Assignment: K Nearest Neighbors Model for the IMDB Movie Review Dataset\n",
        "\n",
        "For the final project, build a K Nearest Neighbors model to predict the sentiment (positive or negative) of movie reviews. The dataset is originally hosted here: http://ai.stanford.edu/~amaas/data/sentiment/\n",
        "\n",
        "Use the notebooks from the class and implement the model, train and test with the corresponding datasets.\n",
        "\n",
        "You can follow these steps:\n",
        "1. Read training-test data (Given)\n",
        "2. Train a KNN classifier (Implement)\n",
        "3. Make predictions on your test dataset (Implement)\n",
        "4. Expermintation (Implement)\n",
        "\n",
        "__You can use the KNN Classifier from here: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf9gzc3NPcHm"
      },
      "source": [
        "## 1. Reading the dataset\n",
        "\n",
        "We will use the __pandas__ library to read our dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R1S95FYPcHm"
      },
      "source": [
        "#### __Training data:__\n",
        "Let's read our training data. Here, we have the text and label fields. Labe is 1 for positive reviews and 0 for negative reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "imYuQ2EcPcHn"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This movie makes me want to throw up every tim...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Listening to the director's commentary confirm...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>One of the best Tarzan films is also one of it...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Valentine is now one of my favorite slasher fi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>No mention if Ann Rivers Siddons adapted the m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  This movie makes me want to throw up every tim...      0\n",
              "1  Listening to the director's commentary confirm...      0\n",
              "2  One of the best Tarzan films is also one of it...      1\n",
              "3  Valentine is now one of my favorite slasher fi...      1\n",
              "4  No mention if Ann Rivers Siddons adapted the m...      0"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv('https://raw.githubusercontent.com/aws-samples/aws-machine-learning-university-accelerated-nlp/master/data/final_project/imdb_train.csv', header=0)\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5c7uQRYPcHn"
      },
      "source": [
        "#### __Test data:__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DiBpa04fPcHo"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What I hoped for (or even expected) was the we...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Garden State must rate amongst the most contri...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>There is a lot wrong with this film. I will no...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>To qualify my use of \"realistic\" in the summar...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dirty War is absolutely one of the best politi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  What I hoped for (or even expected) was the we...      0\n",
              "1  Garden State must rate amongst the most contri...      0\n",
              "2  There is a lot wrong with this film. I will no...      1\n",
              "3  To qualify my use of \"realistic\" in the summar...      1\n",
              "4  Dirty War is absolutely one of the best politi...      1"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "test_df = pd.read_csv('https://raw.githubusercontent.com/aws-samples/aws-machine-learning-university-accelerated-nlp/master/data/final_project/imdb_test.csv', header=0)\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n7O1xvmPcHp"
      },
      "source": [
        "## 2. Train a KNN Classifier\n",
        "Here, you will apply pre-processing operations we covered in the class. Then, you can split your dataset to training and validation here. For your first submission, you will use __K Nearest Neighbors Classifier__. It is available [here](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5f90bOZGPcHp"
      },
      "outputs": [],
      "source": [
        "# Implement this\n",
        "import nltk\n",
        "import re\n",
        "import gensim\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "#\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "#\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Let's get a list of stop words from the NLTK library\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "# These words are important for our problem. We don't want to remove them.\n",
        "excluding = ['against', 'not', 'don', \"don't\",'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\",'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
        "\n",
        "# New stop word list\n",
        "stop_words = [word for word in stop if word not in excluding]\n",
        "\n",
        "snow = SnowballStemmer('english')\n",
        "\n",
        "def process_text(texts):\n",
        "    final_text_list=[]\n",
        "\n",
        "    for sent in texts:\n",
        "        # Check if the sentence is a missing value\n",
        "        if isinstance(sent, str) == False:\n",
        "            sent = \"\"\n",
        "\n",
        "        filtered_sentence=[]\n",
        "\n",
        "        sent = sent.lower() # Lowercase\n",
        "        sent = sent.strip() # Remove leading/trailing whitespace\n",
        "        sent = re.sub('\\s+', ' ', sent) # Remove extra space and tabs\n",
        "        sent = re.compile('<.*?>').sub('', sent) # Remove HTML tags/markups:\n",
        "\n",
        "        for w in word_tokenize(sent):\n",
        "            # We are applying some custom filtering here, feel free to try different things\n",
        "            # Check if it is not numeric and its length>2 and not in stop words\n",
        "            if(not w.isnumeric()) and (len(w)>2) and (w not in stop_words):\n",
        "                # Stem and add to filtered list\n",
        "                filtered_sentence.append(snow.stem(w))\n",
        "        final_string = \" \".join(filtered_sentence) #final string of cleaned words\n",
        "\n",
        "        final_text_list.append(final_string)\n",
        "\n",
        "    return final_text_list\n",
        "\n",
        "X=df[[\"reviewText\"]]\n",
        "Y=df[\"isPositive\"]\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.10, shuffle=True, random_state=324)\n",
        "\n",
        "### PIPELINE ###\n",
        "##########################\n",
        "w2v = gensim.models.Word2Vec()\n",
        "pipeline = Pipeline([\n",
        "    ('text_vect', CountVectorizer(binary=True,\n",
        "    #( 'text_vect', TfidfVectorizer(use_idf=True,\n",
        "                                  max_features=10)),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "                                ])\n",
        "\n",
        "\n",
        "# Visualize the pipeline\n",
        "# This will come in handy especially when building more complex pipelines, stringing together multiple preprocessing steps\n",
        "from sklearn import set_config\n",
        "set_config(display='diagram')\n",
        "pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rieXB-QtPcHq"
      },
      "source": [
        "## 3. Make predictions on your test dataset\n",
        "\n",
        "Once we select our best performing model, we can use it to make predictions on the test dataset. You can simply use __.fit()__ function with your training data to use the best performing K value and use __.predict()__ with your test data to get your test predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BssNQEfAPcHq"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_text_list' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Implement this\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_text_list\u001b[49m\n\u001b[0;32m      3\u001b[0m X_val \u001b[38;5;241m=\u001b[39m val_text_list\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Fit the Pipeline to training data\u001b[39;00m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'train_text_list' is not defined"
          ]
        }
      ],
      "source": [
        "# Implement this\n",
        "X_train = train_text_list\n",
        "X_val = val_text_list\n",
        "\n",
        "# Fit the Pipeline to training data\n",
        "pipeline.fit(X_train, y_train.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lhp8mXM_Ax8d"
      },
      "source": [
        "## 4. Experimentation\n",
        "\n",
        "For each of the following tasks, track both the **weighted F1-score** and **accuracy**:\n",
        "\n",
        "1. **Change the binary parameter in CountVectorizer**: Test both `binary=True` and `binary=False`, and evaluate performance.\n",
        "2. **Switch to TfidfVectorizer**: Replace the CountVectorizer with TfidfVectorizer and compare results.\n",
        "3. **Adjust the max_features**: Experiment with different values of `max_features` for both TfidfVectorizer and CountVectorizer (`binary=True`).\n",
        "4. **Optimize KNN**: Select the best-performing model from task 3 and vary the number of neighbors (`n_neighbors`) in the KNN classifier.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RpHvtEWCVB1"
      },
      "outputs": [],
      "source": [
        "# Task 1\n",
        "\n",
        "# Implement this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bNcCQ2PCfiu"
      },
      "outputs": [],
      "source": [
        "# Task 2\n",
        "\n",
        "# Implement this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_bnccPMCgM9"
      },
      "outputs": [],
      "source": [
        "# Task 3\n",
        "\n",
        "# Implement this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OL1koC0RChNf"
      },
      "outputs": [],
      "source": [
        "# Task 4\n",
        "\n",
        "# Implement this"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
